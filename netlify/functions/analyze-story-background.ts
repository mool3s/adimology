import { 
  updateAgentStory, 
  createBackgroundJobLog, 
  appendBackgroundJobLogEntry, 
  updateBackgroundJobLog 
} from '../../lib/supabase';
import { GoogleGenAI, ThinkingLevel } from '@google/genai';

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;

// Interface for grounding metadata from Google Search
interface GroundingChunk {
  web?: {
    uri: string;
    title: string;
  };
}

interface GroundingMetadata {
  groundingChunks?: GroundingChunk[];
  webSearchQueries?: string[];
}

interface SourceCitation {
  title: string;
  uri: string;
}

export default async (req: Request) => {
  const startTime = Date.now();
  let jobLogId: number | null = null;
  const url = new URL(req.url);
  const emiten = url.searchParams.get('emiten')?.toUpperCase();
  const storyId = url.searchParams.get('id');

  console.log('[Agent Story] Starting background analysis with Gemini 3...');

  try {
    if (!emiten || !storyId) {
      return new Response(JSON.stringify({ error: 'Missing emiten or id' }), { status: 400 });
    }

    // Create job log entry
    try {
      const jobLog = await createBackgroundJobLog('analyze-story', 1);
      jobLogId = jobLog.id;
      if (jobLogId) {
        await appendBackgroundJobLogEntry(jobLogId, {
          level: 'info',
          message: `Starting AI Story Analysis`,
          emiten,
        });
      }
    } catch (logError) {
      console.error('[Agent Story] Failed to create job log:', logError);
    }

    let keyStatsData = null;
    try {
      const body = await req.json();
      keyStatsData = body.keyStats;
    } catch (e) {
      console.log('[Agent Story] No JSON body found or invalid JSON');
    }

    if (!GEMINI_API_KEY) {
      const errMsg = 'GEMINI_API_KEY not configured';
      await updateAgentStory(parseInt(storyId), {
        status: 'error',
        error_message: errMsg
      });
      
      if (jobLogId) {
        await updateBackgroundJobLog(jobLogId, {
          status: 'failed',
          error_message: errMsg,
        });
      }
      
      return new Response(JSON.stringify({ error: 'API key not configured' }), { status: 500 });
    }

    // Update agent story status to processing
    await updateAgentStory(parseInt(storyId), { status: 'processing' });

    if (jobLogId) {
      await appendBackgroundJobLogEntry(jobLogId, {
        level: 'info',
        message: `Analyzing using Gemini 3 Flash Preview (Thinking HIGH)...`,
        emiten,
      });
    }

    const ai = new GoogleGenAI({
      apiKey: GEMINI_API_KEY,
    });

    // Google Search tool for grounding citations
    const googleSearchTool = {
      googleSearch: {},
    };

    // Config with tools and (optionally) Thinking logic
    // Using gemini-3-flash-preview which supports both
    const config = {
      tools: [googleSearchTool],
      thinkingConfig: {
        thinkingLevel: ThinkingLevel.HIGH,
      },
    };

    const today = new Date().toLocaleDateString('id-ID', { day: 'numeric', month: 'long', year: 'numeric' });
    const model = 'gemini-3-flash-preview';
    const systemPrompt = "Kamu adalah seorang analis saham profesional Indonesia yang ahli dalam menganalisa story dan katalis pergerakan harga saham.";
    
    let keyStatsContext = '';
    if (keyStatsData) {
      keyStatsContext = `\nDATA KEY STATISTICS UNTUK ${emiten}:\n` + JSON.stringify(keyStatsData, null, 2) + '\n';
    }

    // Grounding will automatically provide citations for findings
    const userPrompt = `Hari ini adalah ${today}.
Cari dan analisa berita-berita TERBARU (1-2 minggu terakhir) tentang emiten saham Indonesia dengan kode ${emiten} dari internet menggunakan Google Search. 

FOKUS ANALISA:
1. Fokus sepenuhnya pada STORY BISNIS, AKSI KORPORASI, KATALIS fundamental, SENTIMEN PASAR, dan berita-berita TERBARU (1-2 minggu terakhir) baik yang positif maupun negatif.
2. ABAIKAN data harga saham (price action) karena data harga dari internet seringkali tidak akurat atau delay. Jangan menyebutkan angka harga saham spesifik dalam analisis.
3. Hubungkan berita yang ditemukan dengan logika pasar: mengapa berita ini bagus atau buruk untuk masa depan perusahaan?
4. Sebutkan tanggal rilis berita yang kamu gunakan sebagai referensi di dalam deskripsi katalis.
5. Terjemahkan data Key Statistics (${keyStatsContext}) ke dalam bahasa yang mudah dipahami tapi detail untuk trading & investasi. Berikan kesimpulan apakah data tersebut memberikan signal 'Positif/Sehat', 'Neutral', atau 'Negatif/Hati-hati' untuk trading/investasi jangka pendek dan panjang.

Berikan analisis dalam format JSON dengan struktur berikut (PASTIKAN HANYA OUTPUT JSON, tanpa markdown code block agar mudah di-parse):
{
  "matriks_story": [
    {
      "kategori_story": "Transformasi Bisnis | Aksi Korporasi | Pemulihan Fundamental | Kondisi Makro | Sentimen Pasar",
      "deskripsi_katalis": "deskripsi singkat katalis",
      "logika_ekonomi_pasar": "penjelasan logika ekonomi/pasar",
      "potensi_dampak_harga": "dampak terhadap harga saham negatif/netral/positif dan alasan"
    }
  ],
  "swat_analysis": {
    "strengths": ["kekuatan perusahaan"],
    "weaknesses": ["kelemahan perusahaan"],
    "opportunities": ["peluang pasar"],
    "threats": ["ancaman/risiko"]
  },
  "checklist_katalis": [
    {
      "item": "katalis yang perlu dipantau",
      "dampak_instan": "dampak jika terjadi"
    }
  ],
  "strategi_trading": {
    "tipe_saham": "jenis saham (growth/value/turnaround/dll)",
    "target_entry": "area entry yang disarankan",
    "exit_strategy": {
      "take_profit": "target take profit",
      "stop_loss": "level stop loss"
    }
  },
  "keystat_signal": "analisis data key statistics dalam bahasa awam dengan indikasi signal investasi",
  "kesimpulan": "kesimpulan analisis dalam 2-3 kalimat"
}`;

    // Execute generateContent
    const response = await ai.models.generateContent({
      model,
      contents: `${systemPrompt}\n\n${userPrompt}`,
      config,
    });

    // Extract text from response
    const fullText = response.text || '';

    // Extract grounding chunks from response
    // According to SDK, it should be in response.candidates[0].groundingMetadata or response.groundingMetadata
    const groundingMetadata = response.candidates?.[0]?.groundingMetadata || (response as any).groundingMetadata || {};
    const groundingChunks = groundingMetadata.groundingChunks || [];
    
    // Process results into valid citations
    const sources: SourceCitation[] = groundingChunks
      .filter((chunk: GroundingChunk) => chunk.web?.uri)
      .map((chunk: GroundingChunk) => ({
        title: chunk.web?.title || 'Sumber Berita',
        uri: chunk.web?.uri || ''
      }))
      .filter((source: SourceCitation) => source.uri.length > 0);

    console.log(`[Agent Story] Analysis success. Grounding metadata segments: ${groundingMetadata.groundingSupports?.length || 0}. Sources found: ${sources.length}`);

    if (jobLogId) {
      await appendBackgroundJobLogEntry(jobLogId, {
        level: 'info',
        message: `Gemini response received, parsing results... (${sources.length} sources found)`,
        emiten,
      });
    }

    // Parse JSON from response
    let analysisResult;
    try {
      const jsonMatch = fullText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        analysisResult = JSON.parse(jsonMatch[0]);
      } else {
        throw new Error('No JSON found in response');
      }
    } catch (parseError) {
      const errMsg = 'Failed to parse AI response';
      console.error('[Agent Story] Parse error:', parseError);
      
      await updateAgentStory(parseInt(storyId), {
        status: 'error',
        error_message: errMsg
      });

      if (jobLogId) {
        await appendBackgroundJobLogEntry(jobLogId, {
          level: 'error',
          message: errMsg,
          emiten,
          details: { raw: fullText.substring(0, 500) }
        });
        await updateBackgroundJobLog(jobLogId, {
          status: 'failed',
          error_message: errMsg,
        });
      }

      return new Response(JSON.stringify({ error: 'Parse error' }), { status: 500 });
    }

    // Save successful result with sources
    await updateAgentStory(parseInt(storyId), {
      status: 'completed',
      matriks_story: analysisResult.matriks_story || [],
      swot_analysis: analysisResult.swot_analysis || {},
      checklist_katalis: analysisResult.checklist_katalis || [],
      keystat_signal: analysisResult.keystat_signal || '',
      strategi_trading: analysisResult.strategi_trading || {},
      kesimpulan: analysisResult.kesimpulan || '',
      sources: sources // Add grounding sources
    });

    const duration = (Date.now() - startTime) / 1000;
    console.log(`[Agent Story] Analysis completed for ${emiten} in ${duration}s`);

    if (jobLogId) {
      await appendBackgroundJobLogEntry(jobLogId, {
        level: 'info',
        message: `Analysis completed successfully`,
        emiten,
        details: { duration_seconds: duration, sources_count: sources.length }
      });
      await updateBackgroundJobLog(jobLogId, {
        status: 'completed',
        success_count: 1,
        metadata: { duration_seconds: duration, sources_count: sources.length }
      });
    }

    return new Response(JSON.stringify({ success: true, emiten }), { status: 200 });

  } catch (error) {
    const errMsg = String(error);
    console.error('[Agent Story] Critical error:', error);
    
    if (jobLogId) {
      await appendBackgroundJobLogEntry(jobLogId, {
        level: 'error',
        message: `Analysis failed: ${errMsg}`,
        emiten,
      });
      await updateBackgroundJobLog(jobLogId, {
        status: 'failed',
        error_message: errMsg,
      });
    }

    if (storyId) {
      await updateAgentStory(parseInt(storyId), {
        status: 'error',
        error_message: errMsg
      });
    }

    return new Response(JSON.stringify({ error: errMsg }), { status: 500 });
  }
};
